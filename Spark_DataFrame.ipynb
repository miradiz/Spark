{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark DataFrame:\n",
    "\n",
    "In this project, I will be experimenting with Spark DataFrame. Since Spark RDD object is not so suitable for structured data, I will use Spark DataFrame for basic data manipulation. Mainly, I will compare Spark DataFrame to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/Users/miradiz/Downloads/spark-3.1.2-bin-hadoop3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.context.SparkContext"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Instantiate SparkContext to as sc\n",
    "sc = pyspark.SparkContext()\n",
    "type(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD:\n",
    "One way to read a file into RDD is to use SparkContext object. But RDD doesn't provide columns and rows which makes it less structured compared to pandas.DataFrame object. Let's read the json file into RDD using SparkContext object for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"females\": 1994141, \"total\": 4079669, \"males\": 2085528, \"age\": 0, \"year\": 2010}',\n",
       " '{\"females\": 1997991, \"total\": 4085341, \"males\": 2087350, \"age\": 1, \"year\": 2010}',\n",
       " '{\"females\": 2000746, \"total\": 4089295, \"males\": 2088549, \"age\": 2, \"year\": 2010}',\n",
       " '{\"females\": 2002756, \"total\": 4092221, \"males\": 2089465, \"age\": 3, \"year\": 2010}',\n",
       " '{\"females\": 2004366, \"total\": 4094802, \"males\": 2090436, \"age\": 4, \"year\": 2010}']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwe = sc.textFile(\"census_2010.json\")\n",
    "qwe.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The data above is of RDD class\n",
    "type(qwe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark DataFrame:\n",
    "\n",
    "The Spark SQL class is very powerful. It gives Spark more information about the data structure we're using and the computations we want to perform. Spark uses that information to optimize processes.\n",
    "To take advantage of these features, we'll have to use the SQLContext object to structure external data as a DataFrame, instead of the SparkContext object.\n",
    "\n",
    "We can query Spark DataFrame objects with SQL, which we'll explore in the next lesson. The SQLContext class gets its name from this capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.context.SQLContext"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlCtx = SQLContext(sc)\n",
    "type(sqlCtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+-------+----+\n",
      "|age|females|  males|  total|year|\n",
      "+---+-------+-------+-------+----+\n",
      "|  0|1994141|2085528|4079669|2010|\n",
      "|  1|1997991|2087350|4085341|2010|\n",
      "|  2|2000746|2088549|4089295|2010|\n",
      "|  3|2002756|2089465|4092221|2010|\n",
      "|  4|2004366|2090436|4094802|2010|\n",
      "+---+-------+-------+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlCtx.read.json(\"census_2010.json\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The data above is of sql.dataframe class\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- females: long (nullable = true)\n",
      " |-- males: long (nullable = true)\n",
      " |-- total: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Let's see the schema of the table \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas.DataFrame vs pyspark.DataFrame:\n",
    "Pandas and Spark DataFrames also have different underlying data structures. Pandas DataFrames are built around Series objects, while Spark DataFrames are built around RDDs. We can perform most of the same computations and transformations on Spark DataFrames that we can on pandas DataFrames, but the styles and methods are different. Unlike pandas DataFrames, however, Spark DataFrames are immutable, which means we can't modify existing objects. Instead, most transformations on an object return a new DataFrame reflecting the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|  males|\n",
      "+---+-------+\n",
      "|  0|2085528|\n",
      "|  1|2087350|\n",
      "|  2|2088549|\n",
      "|  3|2089465|\n",
      "|  4|2090436|\n",
      "+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## If we don't use show() method it won't print the result because of lazy loading advantage\n",
    "## Let's look at columns: age and males\n",
    "df.select('age', 'males').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Let's look at age column\n",
    "df.select('age').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+-------+----+\n",
      "|age|females|  males|  total|year|\n",
      "+---+-------+-------+-------+----+\n",
      "|  6|2007781|2093905|4101686|2010|\n",
      "|  7|2010281|2097080|4107361|2010|\n",
      "|  8|2013771|2101670|4115441|2010|\n",
      "|  9|2018603|2108014|4126617|2010|\n",
      "| 10|2023289|2114217|4137506|2010|\n",
      "+---+-------+-------+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## In pandas, we used Boolean filtering to select only the rows we wanted. \n",
    "## Spark preserves the very same functionality and notation.\n",
    "## Rows where age is more than 5\n",
    "df[df['age'] > 5].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2010|\n",
      "|2010|\n",
      "|2010|\n",
      "|2010|\n",
      "|2010|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Let's look at the year column only with the same condition as above\n",
    "df[df['age'] > 5][['year']].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2010|\n",
      "|2010|\n",
      "|2010|\n",
      "|2010|\n",
      "|2010|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The same as above (v2)\n",
    "df[df['age'] > 5].select('year').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+-------+----+\n",
      "|age|females|  males|  total|year|\n",
      "+---+-------+-------+-------+----+\n",
      "|  0|1994141|2085528|4079669|2010|\n",
      "|  1|1997991|2087350|4085341|2010|\n",
      "|  2|2000746|2088549|4089295|2010|\n",
      "|  3|2002756|2089465|4092221|2010|\n",
      "|  4|2004366|2090436|4094802|2010|\n",
      "+---+-------+-------+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Display the rows where number of males are higher than females\n",
    "df[df['males'] > df['females']].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>females</th>\n",
       "      <th>males</th>\n",
       "      <th>total</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1994141</td>\n",
       "      <td>2085528</td>\n",
       "      <td>4079669</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1997991</td>\n",
       "      <td>2087350</td>\n",
       "      <td>4085341</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000746</td>\n",
       "      <td>2088549</td>\n",
       "      <td>4089295</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2002756</td>\n",
       "      <td>2089465</td>\n",
       "      <td>4092221</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2004366</td>\n",
       "      <td>2090436</td>\n",
       "      <td>4094802</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  females    males    total  year\n",
       "0    0  1994141  2085528  4079669  2010\n",
       "1    1  1997991  2087350  4085341  2010\n",
       "2    2  2000746  2088549  4089295  2010\n",
       "3    3  2002756  2089465  4092221  2010\n",
       "4    4  2004366  2090436  4094802  2010"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's convert Spark DataFrame into Pandas DataFrame\n",
    "pandas_df = df.toPandas()\n",
    "pandas_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
